{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a230d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "import pandas as pd\n",
    "import corner\n",
    "\n",
    "# For GECCO formatting\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "matplotlib.rcParams['text.usetex'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c290556b",
   "metadata": {},
   "source": [
    "# Different length of backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04d148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = '../../ESR/esr/function_library/core_maths/'\n",
    "all_p = [[], [], []]\n",
    "\n",
    "for c in range(1, 11):\n",
    "    \n",
    "    print(c)\n",
    "\n",
    "    logpar = np.loadtxt(dirname + f'compl_{c}/logconst_{c}.txt')\n",
    "    \n",
    "    for i in range(len(all_p)):\n",
    "        p = np.loadtxt(dirname + f'compl_{c}/katz_codelen_{i+1}_{c}.txt')\n",
    "        p -= logpar\n",
    "        all_p[i] += list(p)\n",
    "print('Loaded')\n",
    "      \n",
    "# Get finite values only\n",
    "all_p = np.array(all_p, dtype=float)\n",
    "m = np.ones(all_p.shape[1], dtype=bool) \n",
    "for i in range(all_p.shape[0]):\n",
    "    m *= np.isfinite(all_p[i])\n",
    "all_p = all_p[:,m]\n",
    "print('Got finite')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea97e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = [f'$- \\log P (f_i | n={i+1})$' for i in range(all_p.shape[0])]\n",
    "    \n",
    "fig, axs = plt.subplots(all_p.shape[0], all_p.shape[0], figsize=(6,6), sharex=True)\n",
    "\n",
    "for i in range(all_p.shape[0]):\n",
    "    for j in range(i+1, all_p.shape[0]):\n",
    "        plt.setp(axs[i,j].get_xticklines(), visible=False)\n",
    "\n",
    "print('Making corner')\n",
    "corner.corner(all_p.transpose(),\n",
    "            labels=labs,\n",
    "            fig=fig,\n",
    "            label_kwargs={'fontsize':12},\n",
    "            plot_contours=False,\n",
    "            plot_density=False,\n",
    "            plot_datapoints=False)\n",
    "\n",
    "bins = np.logspace(0, np.log10(all_p.shape[1]))\n",
    "\n",
    "print('Hexbin')\n",
    "for i in range(all_p.shape[0]-1):\n",
    "    for j in range(i+1, all_p.shape[0]):\n",
    "        print(i, j)\n",
    "        hb = axs[j,i].hexbin(all_p[i,:], all_p[j,:], mincnt=1, gridsize=40, bins='log')\n",
    "        x = axs[j,i].get_xlim()\n",
    "        axs[j,i].plot(x, x, color='r', lw=1)\n",
    "        \n",
    "for i in range(all_p.shape[0]):\n",
    "    axs[i,i].clear()\n",
    "    for j in range(all_p.shape[0]):\n",
    "        if i == j:\n",
    "            kwargs = {'color':'k',\n",
    "                    'zorder':1,\n",
    "                    'alpha':1,\n",
    "                    'lw':1,\n",
    "            }\n",
    "        else:\n",
    "            kwargs = {'color':'r',\n",
    "                    'zorder':0,\n",
    "                    'alpha':0.5,\n",
    "                    'lw':0.75,\n",
    "            }\n",
    "        axs[i,i].hist(all_p[j,:], bins=30, density=True, histtype='step', **kwargs)\n",
    "    axs[i,i].set_yticks([])\n",
    "    \n",
    "for i in range(axs.shape[0]):\n",
    "    axs[-1,i].set_xlabel(r'%s'%labs[i])\n",
    "\n",
    "ax2_divider = make_axes_locatable(axs[-2,-1])\n",
    "cax2 = ax2_divider.append_axes(\"left\", size=\"7%\", pad=\"2%\")\n",
    "cb = fig.colorbar(hb, cax=cax2, orientation=\"vertical\")\n",
    "cb.set_label(r'Number of functions')\n",
    "\n",
    "\n",
    "axs[0,0].set_xlim(0, 50)\n",
    "\n",
    "fig.savefig('../figs/backoff_length.pdf', bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923b8f1e",
   "metadata": {},
   "source": [
    "# Benchmark testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecc8caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'korns_4'; true_eq = 'a0 + a1*sin(x)'\n",
    "all_N = np.array([10, 30, 100, 300, 1000, 3000, 10000])\n",
    "frac_sigx = 0.5\n",
    "nsamp = 5\n",
    "method_labels = ['Likelihood', 'Score', 'MDL', 'MDL Language Model', 'MDL FBF + Language Model', 'Bayes FBF + Language Model']\n",
    "all_linthresh = [0.1, 1e5, 1, 1, 1, 1]\n",
    "\n",
    "delta_loss = np.empty((6, len(all_N), nsamp))\n",
    "has_truth = np.empty(delta_loss.shape, dtype=bool)\n",
    "\n",
    "for i, nx in enumerate(all_N):\n",
    "    for samp in range(nsamp):\n",
    "        fname = f'{name}_{nx}_{frac_sigx}_{samp}'\n",
    "        print(fname)\n",
    "        d = pd.read_csv(f'../scripts/output/output_{fname}/selection_summary.csv', delimiter=';')\n",
    "        for j in range(delta_loss.shape[0]):\n",
    "            f0 = d['f0'][j]\n",
    "            f1 = d['f1'][j]\n",
    "            ftrue = d['ftrue'][j]\n",
    "            has_truth[j,i,samp] = ((f0 == ftrue) or (f1 == ftrue))\n",
    "            if f0 == ftrue:\n",
    "                delta_loss[j,i,samp] = d['loss1'][j] - d['loss0'][j]\n",
    "            elif f1 == ftrue:\n",
    "                delta_loss[j,i,samp] = d['loss0'][j] - d['loss1'][j]\n",
    "            else:\n",
    "                delta_loss[j,i,samp] = d['loss0'][j] - d['losstrue'][j]\n",
    "\n",
    "fig, axs = plt.subplots(2, int(np.ceil(delta_loss.shape[0]/2)), figsize=(10,4), sharex=True)\n",
    "for i in range(axs.shape[0]):\n",
    "    axs[i,0].set_ylabel('Preference for the truth')\n",
    "for i in range(axs.shape[1]):\n",
    "    axs[-1,i].set_xlabel('Number of data points')\n",
    "axs = axs.flatten()\n",
    "cm = plt.get_cmap('Set1')\n",
    "for i in range(delta_loss.shape[0]):\n",
    "    for j in range(delta_loss.shape[2]):\n",
    "        axs[i].semilogx(all_N[has_truth[i,:,j]], delta_loss[i,has_truth[i,:,j],j], '.', color=cm(0))\n",
    "        axs[i].semilogx(all_N[~has_truth[i,:,j]], delta_loss[i,~has_truth[i,:,j],j], '.', color=cm(1))\n",
    "    axs[i].set_yscale('symlog', linthresh=all_linthresh[i])\n",
    "    axs[i].axhline(y=0, color='k')\n",
    "    axs[i].set_title(method_labels[i])\n",
    "    axs[i].tick_params(labelbottom=True)\n",
    "    \n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "ntop2 = np.sum(has_truth, axis=(1,2))\n",
    "for i in range(len(ntop2)):\n",
    "    print('Method %s: %i of %i have truth in top 2'%(method_labels[i],ntop2[i],nsamp*len(all_N)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caef581",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_name = ['nguyen_8', 'korns_4', 'korns_7']\n",
    "all_truth = {\n",
    "    'nguyen_8':r'$y = \\sqrt{x}$',\n",
    "    'korns_4':r'$y = -2.13 + 0.13 \\sin(x)$',\n",
    "    'korns_7':r'$y = 213.81 (1 - e^{-0.547 x})$',\n",
    "}\n",
    "\n",
    "names_as_columns = False; figsize=(10,4); hspace=0.15; wspace=0.4\n",
    "names_as_columns = True; figsize = (10,5); hspace=0.12; wspace=0.2\n",
    "\n",
    "all_N = np.array([10, 30, 100, 300, 1000, 3000, 10000])\n",
    "xticks = [10, 100, 1000, 10000]\n",
    "frac_sigx = 0.5\n",
    "nsamp = 5\n",
    "method_labels = ['Likelihood', 'Score', 'MDL', 'MDL\\n+LM', \n",
    "                 'MDL\\n+FBF\\n+LM', 'Bayes\\n+FBF\\n+LM']\n",
    "\n",
    "if names_as_columns:\n",
    "    fig, axs = plt.subplots(len(method_labels), len(all_name), figsize=figsize, sharex=True)\n",
    "else:\n",
    "    fig, axs = plt.subplots(len(all_name), len(method_labels), figsize=figsize, sharex=True)\n",
    "cm = plt.get_cmap('Set1')\n",
    "\n",
    "for bnum, name in enumerate(all_name):\n",
    "    \n",
    "    print(f'\\n{name}')\n",
    "\n",
    "    if names_as_columns:\n",
    "        axs[0, bnum].set_title(r'%s: '%name + all_truth[name])\n",
    "    else:\n",
    "        axs[bnum, 0].set_ylabel(name)\n",
    "    \n",
    "    delta_loss = np.empty((len(method_labels), len(all_N), nsamp))\n",
    "    has_truth = np.empty(delta_loss.shape, dtype=bool)\n",
    "    truth_top = np.empty(delta_loss.shape, dtype=bool)\n",
    "\n",
    "    for i, nx in enumerate(all_N):\n",
    "        for samp in range(nsamp):\n",
    "            fname = f'{name}_{nx}_{frac_sigx}_{samp}'\n",
    "            d = pd.read_csv(f'../scripts/output/output_{fname}/selection_summary.csv', delimiter=';')\n",
    "            for j in range(delta_loss.shape[0]):\n",
    "                f0 = d['f0'][j]\n",
    "                f1 = d['f1'][j]\n",
    "                ftrue = d['ftrue'][j]\n",
    "                has_truth[j,i,samp] = ((f0 == ftrue) or (f1 == ftrue))\n",
    "                truth_top[j,i,samp] = (f0 == ftrue)\n",
    "                if j == 1:\n",
    "                    if f0 == ftrue:\n",
    "                        delta_loss[j,i,samp] = np.log(np.abs(d['loss1'][j])) - np.log(np.abs(d['loss0'][j]))\n",
    "                    elif f1 == ftrue:\n",
    "                        delta_loss[j,i,samp] = np.log(np.abs(d['loss0'][j])) - np.log(np.abs(d['loss1'][j]))\n",
    "                    else:\n",
    "                        delta_loss[j,i,samp] = np.log(np.abs(d['loss0'][j])) - np.log(np.abs(d['losstrue'][j]))\n",
    "                    delta_loss[j,i,samp] *= -1\n",
    "                else:\n",
    "                    if f0 == ftrue:\n",
    "                        delta_loss[j,i,samp] = d['loss1'][j] - d['loss0'][j]\n",
    "                    elif f1 == ftrue:\n",
    "                        delta_loss[j,i,samp] = d['loss0'][j] - d['loss1'][j]\n",
    "                    else:\n",
    "                        delta_loss[j,i,samp] = d['loss0'][j] - d['losstrue'][j]\n",
    "                    if not np.isfinite(delta_loss[j,i,samp]):\n",
    "                        print(\"BAD\", j, name, nx, samp)\n",
    "    \n",
    "    for i in range(delta_loss.shape[0]):\n",
    "        for j in range(delta_loss.shape[2]):\n",
    "            if names_as_columns:\n",
    "                axs[i,bnum].semilogx(all_N[has_truth[i,:,j]], delta_loss[i,has_truth[i,:,j],j], '.', color=cm(0))\n",
    "                axs[i,bnum].semilogx(all_N[~has_truth[i,:,j]], delta_loss[i,~has_truth[i,:,j],j], '.', color=cm(1))\n",
    "            else:\n",
    "                axs[bnum, i].semilogx(all_N[has_truth[i,:,j]], delta_loss[i,has_truth[i,:,j],j], '.', color=cm(0))\n",
    "                axs[bnum, i].semilogx(all_N[~has_truth[i,:,j]], delta_loss[i,~has_truth[i,:,j],j], '.', color=cm(1))\n",
    "        if names_as_columns:\n",
    "            axs[i,bnum].axhline(y=0, color='k')\n",
    "            axs[i,bnum].set_xticks(xticks)\n",
    "        else:\n",
    "            axs[bnum,i].axhline(y=0, color='k')\n",
    "            axs[bnum,i].set_xticks(xticks)\n",
    "        \n",
    "    ntop2 = np.sum(has_truth, axis=(1,2))\n",
    "    truth_top = np.sum(truth_top, axis=(1,2))\n",
    "    for i in range(len(ntop2)):\n",
    "        print('Method %s: %i of %i have truth in top 2'%(method_labels[i].replace('\\n',''),ntop2[i],nsamp*len(all_N)))\n",
    "    print('')    \n",
    "    for i in range(len(ntop2)):\n",
    "        print('Method %s: %i of %i has truth top'%(method_labels[i].replace('\\n',''),truth_top[i],nsamp*len(all_N)))\n",
    "        \n",
    "for ax in axs.flatten():\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    if ymax < 0:\n",
    "        ymax = abs(ymin)\n",
    "    else:\n",
    "        ymax = max(abs(ymin), abs(ymax))\n",
    "    ymax *= 1.1\n",
    "    ax.set_ylim(-ymax, ymax)\n",
    "\n",
    "if names_as_columns:\n",
    "    for i in range(axs.shape[0]):\n",
    "        axs[i,0].set_ylabel(method_labels[i], fontsize=10)\n",
    "else:\n",
    "    for i in range(axs.shape[1]):\n",
    "        axs[0,i].set_title(method_labels[i], fontsize=10)\n",
    "        \n",
    "for i in range(axs.shape[1]):\n",
    "    axs[-1,i].set_xlabel('Number of data points')\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "fig.align_ylabels(axs[:,0])\n",
    "        \n",
    "fig.savefig('../figs/benchmark_results.pdf', bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8797726f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6393ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
